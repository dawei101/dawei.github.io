---
id: 11
title: Scrapy
date: 2013-09-16T16:27:54+00:00
author: dawei
layout: post
guid: http://bookwikiup.com/blog/?p=11
permalink: /2013/09/16/scrapy/
categories:
  - 未分类
---
用了一些Scrapy做的爬虫, 但对工作中用到的实现很排斥, 在重构之初建议很多次, 但以前外包的代码实现大体如此, 在重构的时候还是没有改掉. 离职最近的闲时间叙述一下观点.

每一个伟大的工具都得有一整套的文档, 文档是使用的开始. Scrapy已经做的很好,而且有现成的文档, 运行也算稳定, 为什么要改变. 在使用第三方框架的时候, 尽量不要去改变它, 你可以耍技碉堡, 但带来的成本很高. 新队友加入是没有文档的,很难让人在很短的时间理解. 敏捷开发, 有多少文档会快速跟进呢, 况且某些碉堡并不一定比现有的实现碉堡.

<ul class="edui-filter-square">
  <li>
    <strong><span class="edui-filter-line-through">减少进程重复建立开销. new一个</span><span class="edui-filter-line-through">Crawler, 装载Spider,然后等待Crawler结束, 返回反馈信息.</span>  这样做没必要.<br /> </strong>
  </li>
</ul>

启动一个进程然后等待进程反馈, 浪费系统开销;  所有的异常或者结果都可以在Crawler里自己搞定, 比如做一个event桥接件, Crawler主动提交结果与反馈, 不要让另一个进程傻傻的等.

<ul class="edui-filter-square">
  <li>
    <strong>结果输出应该用Pipleline</strong>
  </li>
</ul>

Pipeline 在Scrapy里的设计中, 就是为了输出抓取结果, 而且整个Crawler周期里只会实例化一次Pipeline, 开销不大为什么不用.把结果输出放在Spider里, 这样还是太傻了.

&nbsp;

* * *这两天做了个简单的爬虫.


  
Scrapy COMMAND 下对Spider的传参, 对于有类型的参数确实是过于弱智了.如果有需要做一些Update的抓取, 必然要传递相关的update信息过去,这么批量的传参确实会有点丑, 而且所有的参数只能是string型了.</p> 

以下是Scrapy文档中command 方式传参:

<pre>scrapy crawl myspider -a categories='["electronics"]'</pre>

传参就先用json等序列化的串串也还凑合!